{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrida\\AppData\\Local\\Temp\\ipykernel_15404\\3026447886.py:7: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books_df = pd.read_csv('./data/Books.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load your datasets\n",
    "books_df = pd.read_csv('./data/Books.csv')\n",
    "ratings_df = pd.read_csv('./data/Ratings.csv')\n",
    "users_df = pd.read_csv('./data/Users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['ISBN'] = ratings_df['ISBN'].apply(lambda x : str(x))\n",
    "books_df['ISBN'] = books_df['ISBN'].apply(lambda x : str(x))\n",
    "\n",
    "combined_df = pd.merge(ratings_df,books_df,on='ISBN')\n",
    "combined_df = pd.merge(combined_df,users_df,on='User-ID')\n",
    "combined_df.drop(columns=['Image-URL-S','Image-URL-M','Image-URL-L'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Year-Of-Publication'] = pd.to_numeric(combined_df['Year-Of-Publication'], errors='coerce')\n",
    "combined_df.dropna(subset=['Year-Of-Publication'], inplace=True)\n",
    "combined_df['Year-Of-Publication'] = combined_df['Year-Of-Publication'].astype(int)\n",
    "\n",
    "def is_numeric(val):\n",
    "    return isinstance(val, (int, float, np.number))\n",
    "\n",
    "numeric_authors_mask = combined_df['Book-Author'].apply(is_numeric)\n",
    "combined_df = combined_df[~numeric_authors_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>cincinnati, ohio, usa</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2313</td>\n",
       "      <td>0812533550</td>\n",
       "      <td>9</td>\n",
       "      <td>Ender's Game (Ender Wiggins Saga (Paperback))</td>\n",
       "      <td>Orson Scott Card</td>\n",
       "      <td>1986</td>\n",
       "      <td>Tor Books</td>\n",
       "      <td>cincinnati, ohio, usa</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2313</td>\n",
       "      <td>0679745580</td>\n",
       "      <td>8</td>\n",
       "      <td>In Cold Blood (Vintage International)</td>\n",
       "      <td>TRUMAN CAPOTE</td>\n",
       "      <td>1994</td>\n",
       "      <td>Vintage</td>\n",
       "      <td>cincinnati, ohio, usa</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2313</td>\n",
       "      <td>0060173289</td>\n",
       "      <td>9</td>\n",
       "      <td>Divine Secrets of the Ya-Ya Sisterhood : A Novel</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>1996</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>cincinnati, ohio, usa</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2313</td>\n",
       "      <td>0385482388</td>\n",
       "      <td>5</td>\n",
       "      <td>The Mistress of Spices</td>\n",
       "      <td>Chitra Banerjee Divakaruni</td>\n",
       "      <td>1998</td>\n",
       "      <td>Anchor Books/Doubleday</td>\n",
       "      <td>cincinnati, ohio, usa</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating  \\\n",
       "1     2313  034545104X            5   \n",
       "2     2313  0812533550            9   \n",
       "3     2313  0679745580            8   \n",
       "4     2313  0060173289            9   \n",
       "5     2313  0385482388            5   \n",
       "\n",
       "                                         Book-Title  \\\n",
       "1                              Flesh Tones: A Novel   \n",
       "2     Ender's Game (Ender Wiggins Saga (Paperback))   \n",
       "3             In Cold Blood (Vintage International)   \n",
       "4  Divine Secrets of the Ya-Ya Sisterhood : A Novel   \n",
       "5                            The Mistress of Spices   \n",
       "\n",
       "                  Book-Author  Year-Of-Publication               Publisher  \\\n",
       "1                  M. J. Rose                 2002        Ballantine Books   \n",
       "2            Orson Scott Card                 1986               Tor Books   \n",
       "3               TRUMAN CAPOTE                 1994                 Vintage   \n",
       "4               Rebecca Wells                 1996           HarperCollins   \n",
       "5  Chitra Banerjee Divakaruni                 1998  Anchor Books/Doubleday   \n",
       "\n",
       "                Location   Age  \n",
       "1  cincinnati, ohio, usa  23.0  \n",
       "2  cincinnati, ohio, usa  23.0  \n",
       "3  cincinnati, ohio, usa  23.0  \n",
       "4  cincinnati, ohio, usa  23.0  \n",
       "5  cincinnati, ohio, usa  23.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.dropna(inplace=True)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "book_encoder = LabelEncoder()\n",
    "author_encoder = LabelEncoder()\n",
    "publisher_encoder = LabelEncoder()\n",
    "location_encoder = LabelEncoder()\n",
    "\n",
    "combined_df['User-ID'] = user_encoder.fit_transform(combined_df['User-ID'])\n",
    "combined_df['ISBN'] = book_encoder.fit_transform(combined_df['ISBN'])\n",
    "combined_df['Book-Author'] = author_encoder.fit_transform(combined_df['Book-Author'])\n",
    "combined_df['Publisher'] = publisher_encoder.fit_transform(combined_df['Publisher'])\n",
    "combined_df['Location'] = location_encoder.fit_transform(combined_df['Location'])\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = train_test_split(combined_df, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data['Age'] = scaler.fit_transform(train_data[['Age']])\n",
    "test_data['Age'] = scaler.transform(test_data[['Age']])\n",
    "\n",
    "# Fit on training data and transform both training and testing data for 'Year-Of-Publication'\n",
    "train_data['Year-Of-Publication'] = scaler.fit_transform(train_data[['Year-Of-Publication']])\n",
    "test_data['Year-Of-Publication'] = scaler.transform(test_data[['Year-Of-Publication']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>527981</th>\n",
       "      <td>51438</td>\n",
       "      <td>88913</td>\n",
       "      <td>7</td>\n",
       "      <td>The Call of the Wild: And Selected Stories (Si...</td>\n",
       "      <td>35563</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>11806</td>\n",
       "      <td>12041</td>\n",
       "      <td>-1.659782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186300</th>\n",
       "      <td>20704</td>\n",
       "      <td>2767</td>\n",
       "      <td>0</td>\n",
       "      <td>Watermelon</td>\n",
       "      <td>54891</td>\n",
       "      <td>0.146893</td>\n",
       "      <td>9964</td>\n",
       "      <td>6659</td>\n",
       "      <td>0.539582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836300</th>\n",
       "      <td>19142</td>\n",
       "      <td>17733</td>\n",
       "      <td>10</td>\n",
       "      <td>The Further Adventures of Hank the Cowdog (Han...</td>\n",
       "      <td>42532</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>10544</td>\n",
       "      <td>3218</td>\n",
       "      <td>0.823371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567222</th>\n",
       "      <td>26074</td>\n",
       "      <td>32213</td>\n",
       "      <td>9</td>\n",
       "      <td>The Tipping Point: How Little Things Can Make ...</td>\n",
       "      <td>53814</td>\n",
       "      <td>0.138306</td>\n",
       "      <td>7672</td>\n",
       "      <td>2859</td>\n",
       "      <td>-0.737468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383918</th>\n",
       "      <td>43250</td>\n",
       "      <td>111957</td>\n",
       "      <td>9</td>\n",
       "      <td>A Journey in Ladakh: Encounters with Buddhism</td>\n",
       "      <td>3261</td>\n",
       "      <td>0.138306</td>\n",
       "      <td>8101</td>\n",
       "      <td>11302</td>\n",
       "      <td>-1.375993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        User-ID    ISBN  Book-Rating  \\\n",
       "527981    51438   88913            7   \n",
       "186300    20704    2767            0   \n",
       "836300    19142   17733           10   \n",
       "567222    26074   32213            9   \n",
       "383918    43250  111957            9   \n",
       "\n",
       "                                               Book-Title  Book-Author  \\\n",
       "527981  The Call of the Wild: And Selected Stories (Si...        35563   \n",
       "186300                                         Watermelon        54891   \n",
       "836300  The Further Adventures of Hank the Cowdog (Han...        42532   \n",
       "567222  The Tipping Point: How Little Things Can Make ...        53814   \n",
       "383918      A Journey in Ladakh: Encounters with Buddhism         3261   \n",
       "\n",
       "        Year-Of-Publication  Publisher  Location       Age  \n",
       "527981             0.129720      11806     12041 -1.659782  \n",
       "186300             0.146893       9964      6659  0.539582  \n",
       "836300             0.129720      10544      3218  0.823371  \n",
       "567222             0.138306       7672      2859 -0.737468  \n",
       "383918             0.138306       8101     11302 -1.375993  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_locations, num_authors, num_publishers, embed_size):\n",
    "        super(NCF, self).__init__()\n",
    "        # Embeddings for user and item IDs\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=embed_size)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=embed_size)\n",
    "        \n",
    "        # Additional embeddings for categorical features\n",
    "        self.location_embedding = nn.Embedding(num_embeddings=num_locations, embedding_dim=embed_size)\n",
    "        self.author_embedding = nn.Embedding(num_embeddings=num_authors, embedding_dim=embed_size)\n",
    "        self.publisher_embedding = nn.Embedding(num_embeddings=num_publishers, embedding_dim=embed_size)\n",
    "        \n",
    "        # MLP layers\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(embed_size * 5 + 2, 64),  # 5 embeddings + 2 numerical features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, user_ids, item_ids, locations, ages, authors, years, publishers):\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        location_emb = self.location_embedding(locations)\n",
    "        author_emb = self.author_embedding(authors)\n",
    "        publisher_emb = self.publisher_embedding(publishers)\n",
    "        \n",
    "        # Combine all features\n",
    "        combined_features = torch.cat([user_emb, item_emb, location_emb, author_emb, publisher_emb, ages.unsqueeze(1), years.unsqueeze(1)], dim=1)\n",
    "        \n",
    "        # Pass through MLP\n",
    "        predictions = self.fc_layers(combined_features)\n",
    "        return predictions.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 16.6313\n",
      "Epoch [2/10], Loss: 18.3730\n",
      "Epoch [3/10], Loss: 6.3518\n",
      "Epoch [4/10], Loss: 5.4577\n",
      "Epoch [5/10], Loss: 13.5837\n",
      "Epoch [6/10], Loss: 11.4114\n",
      "Epoch [7/10], Loss: 6.6981\n",
      "Epoch [8/10], Loss: 8.8492\n",
      "Epoch [9/10], Loss: 4.1447\n",
      "Epoch [10/10], Loss: 1.0009\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.tensor(df['User-ID'].values, dtype=torch.long)\n",
    "        self.books = torch.tensor(df['ISBN'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df['Book-Rating'].values, dtype=torch.float32)\n",
    "        self.locations = torch.tensor(df['Location'].values, dtype=torch.long)\n",
    "        self.authors = torch.tensor(df['Book-Author'].values, dtype=torch.long)\n",
    "        self.publishers = torch.tensor(df['Publisher'].values, dtype=torch.long)\n",
    "        self.age = torch.tensor(df['Age'].values, dtype=torch.long)\n",
    "        self.year = torch.tensor(df['Year-Of-Publication'].values, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.books[idx], self.ratings[idx], self.locations[idx], self.authors[idx],\\\n",
    "              self.publishers[idx], self.age[idx], self.year[idx]\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataset = RatingsDataset(train_data)\n",
    "test_dataset = RatingsDataset(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NCF(num_users=len(user_encoder.classes_), num_items=len(book_encoder.classes_), num_authors=len(author_encoder.classes_), \\\n",
    "            num_locations=len(location_encoder.classes_), num_publishers=len(publisher_encoder.classes_), embed_size=16).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for user_indices, book_indices, ratings, location, author, publisher, age, year in train_loader:\n",
    "        user_indices, book_indices, ratings = user_indices.to(device), book_indices.to(device), ratings.to(device)\n",
    "        location, author, publisher, age, year = location.to(device), author.to(device), publisher.to(device),\\\n",
    "                                                 age.to(device), year.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(user_indices, book_indices, location, age, author, year, publisher)\n",
    "        loss = criterion(outputs, ratings)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 12.535417493184408\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0\n",
    "with torch.no_grad():  # No gradients needed\n",
    "    for user_indices, book_indices, ratings, location, author, publisher, age, year in test_loader:\n",
    "        user_indices, book_indices, ratings = user_indices.to(device), book_indices.to(device), ratings.to(device)\n",
    "        location, author, publisher, age, year = location.to(device), author.to(device), publisher.to(device),\\\n",
    "                                                 age.to(device), year.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(user_indices, book_indices, location, age, author, year, publisher)\n",
    "        loss = criterion(outputs, ratings)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        predictions.extend(list(zip(user_indices.cpu().numpy(),\n",
    "                                    book_indices.cpu().numpy(),\n",
    "                                    outputs.cpu().numpy(),\n",
    "                                    ratings.cpu().numpy())))\n",
    "\n",
    "# Average loss\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test MSE: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, est, true_r in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        precision[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        recall[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return np.mean(list(precision.values())), np.mean(list(recall.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39776720455287323, 0.41106376766512776)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_at_k(predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate_at_k(predictions, k=10, threshold=4.0):\n",
    "    predictions_array = np.array(predictions)\n",
    "    # Unique users\n",
    "    unique_users = np.unique(predictions_array[:, 0])\n",
    "    \n",
    "    hits = 0\n",
    "    for user in unique_users:\n",
    "        # Filter predictions for the current user\n",
    "        user_predictions = predictions_array[predictions_array[:, 0] == user]\n",
    "        \n",
    "        # Sort the user's predictions by predicted rating in descending order\n",
    "        sorted_user_predictions = user_predictions[user_predictions[:, 2].argsort()[::-1]]\n",
    "        \n",
    "        # Check if the top-K items contain at least one relevant item\n",
    "        top_k = sorted_user_predictions[:k]\n",
    "        if any(top_k[:, 3] >= threshold):  # Check true ratings in top K\n",
    "            hits += 1\n",
    "    \n",
    "    # Calculate hit rate\n",
    "    hit_rate = hits / len(unique_users)\n",
    "    return hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6941712436667092"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate_at_k(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def ndcg_at_k_per_user(predictions, k=10, threshold=3.5):\n",
    "    # Convert to numpy array for easier manipulation\n",
    "    predictions_array = np.array(predictions)\n",
    "    unique_users = np.unique(predictions_array[:, 0])\n",
    "    \n",
    "    ndcg_scores = []\n",
    "    \n",
    "    for user_id in unique_users:\n",
    "        # Filter predictions for the current user\n",
    "        user_preds = predictions_array[predictions_array[:, 0] == user_id]\n",
    "        \n",
    "        # Sort user predictions by predicted rating in descending order\n",
    "        sorted_preds = user_preds[user_preds[:, 2].argsort()[::-1]]\n",
    "        \n",
    "        DCG = 0\n",
    "        IDCG = 0\n",
    "        for i, (_, _, est, true_r) in enumerate(sorted_preds[:k]):\n",
    "            rel = 1 if true_r >= threshold else 0\n",
    "            DCG += (rel / math.log(i + 2, 2))\n",
    "            IDCG += (1 / math.log(i + 2, 2))  # Assuming all top K items are relevant\n",
    "        \n",
    "        ndcg_score = DCG / IDCG if IDCG > 0 else 0\n",
    "        ndcg_scores.append(ndcg_score)\n",
    "    \n",
    "    # Average NDCG across all users\n",
    "    avg_ndcg = np.mean(ndcg_scores) if ndcg_scores else 0\n",
    "    return avg_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5340392259224052"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_k_per_user(predictions=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Books: ['0586092269', '0886777399', '0020303750', '0099296810', '0307204030']\n"
     ]
    }
   ],
   "source": [
    "# def recommend_books(model, user_id_encoded, book_ids_encoded, num_recommendations=5):\n",
    "#     model.eval()\n",
    "#     user_indices = torch.tensor([user_id_encoded] * len(book_ids_encoded), dtype=torch.long).to(device)\n",
    "#     book_indices = torch.tensor(book_ids_encoded, dtype=torch.long).to(device)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         predictions = model(user_indices, book_indices).cpu().numpy()\n",
    "    \n",
    "#     # Get the top N recommendations; argsort sorts in ascending order, so use [-num_recommendations:]\n",
    "#     recommended_indices = np.argsort(predictions)[-num_recommendations:]\n",
    "    \n",
    "#     # Decode book IDs if necessary\n",
    "#     recommended_books = [book_encoder.inverse_transform([idx])[0] for idx in recommended_indices]\n",
    "    \n",
    "#     return recommended_books\n",
    "\n",
    "# # Example usage\n",
    "# user_id_encoded = user_encoder.transform([809])[0]  # Replace 'user_id_example' with actual user ID\n",
    "# book_ids_encoded = list(range(len(book_encoder.classes_)))  # All books\n",
    "# recommended_books = recommend_books(model, user_id_encoded, book_ids_encoded, num_recommendations=5)\n",
    "# print(\"Recommended Books:\", recommended_books)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
