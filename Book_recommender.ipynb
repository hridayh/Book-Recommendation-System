{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hrida\\AppData\\Local\\Temp\\ipykernel_24056\\2657491641.py:6: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books_df = pd.read_csv('./data/Books.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your datasets\n",
    "books_df = pd.read_csv('./data/Books.csv')\n",
    "ratings_df = pd.read_csv('./data/Ratings.csv')\n",
    "users_df = pd.read_csv('./data/Users.csv')\n",
    "\n",
    "# Assuming ratings_df has columns ['user_id', 'book_id', 'rating']\n",
    "# Ensure user_id and book_id in ratings_df are encoded to numeric values\n",
    "user_encoder = LabelEncoder()\n",
    "book_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['User-ID'] = user_encoder.fit_transform(ratings_df['User-ID'])\n",
    "ratings_df['ISBN'] = book_encoder.fit_transform(ratings_df['ISBN'])\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = train_test_split(ratings_df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178554</th>\n",
       "      <td>14710</td>\n",
       "      <td>66197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533905</th>\n",
       "      <td>48732</td>\n",
       "      <td>207194</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091374</th>\n",
       "      <td>98946</td>\n",
       "      <td>65482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036247</th>\n",
       "      <td>93459</td>\n",
       "      <td>128975</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309523</th>\n",
       "      <td>28004</td>\n",
       "      <td>47683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID    ISBN  Book-Rating\n",
       "178554     14710   66197            0\n",
       "533905     48732  207194            8\n",
       "1091374    98946   65482            0\n",
       "1036247    93459  128975            0\n",
       "309523     28004   47683            0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_books, embed_size, layers=[32, 16, 8]):\n",
    "        super(NCF, self).__init__()\n",
    "        \"\"\"\n",
    "        num_users: Number of unique users\n",
    "        num_books: Number of unique books\n",
    "        embed_size: Embedding size\n",
    "        layers: MLP layers sizes\n",
    "        \"\"\"\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=embed_size)\n",
    "        self.book_embedding = nn.Embedding(num_embeddings=num_books, embedding_dim=embed_size)\n",
    "        \n",
    "        # MLP layers\n",
    "        self.MLP_layers = nn.ModuleList()\n",
    "        for in_size, out_size in zip(layers[:-1], layers[1:]):\n",
    "            self.MLP_layers.append(nn.Linear(in_size, out_size))\n",
    "        \n",
    "        # Final layer\n",
    "        self.output_layer = nn.Linear(layers[-1] + embed_size, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, user_indices, book_indices):\n",
    "        # Embeddings\n",
    "        user_embedding = self.user_embedding(user_indices)\n",
    "        book_embedding = self.book_embedding(book_indices)\n",
    "        # Concatenate the embeddings to feed into the MLP\n",
    "        vector = torch.cat([user_embedding, book_embedding], dim=-1)\n",
    "        # Pass through MLP layers\n",
    "        for layer in self.MLP_layers:\n",
    "            vector = layer(vector)\n",
    "            vector = self.relu(vector)\n",
    "        \n",
    "        # Concatenate the output of the GMF part and the MLP part\n",
    "        concat = torch.cat([user_embedding * book_embedding, vector], dim=-1)\n",
    "        \n",
    "        # Final prediction layer\n",
    "        prediction = self.output_layer(concat)\n",
    "        return prediction.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 13.9665\n",
      "Epoch [2/5], Loss: 13.4029\n",
      "Epoch [3/5], Loss: 16.2462\n",
      "Epoch [4/5], Loss: 10.1746\n",
      "Epoch [5/5], Loss: 13.4950\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.tensor(df['User-ID'].values, dtype=torch.long)\n",
    "        self.books = torch.tensor(df['ISBN'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df['Book-Rating'].values, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.books[idx], self.ratings[idx]\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataset = RatingsDataset(train_data)\n",
    "test_dataset = RatingsDataset(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NCF(num_users=len(user_encoder.classes_), num_books=len(book_encoder.classes_), embed_size=16).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for user_indices, book_indices, ratings in train_loader:\n",
    "        user_indices, book_indices, ratings = user_indices.to(device), book_indices.to(device), ratings.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(user_indices, book_indices)\n",
    "        loss = criterion(outputs, ratings)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 11.815114720768575\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0\n",
    "with torch.no_grad():  # No gradients needed\n",
    "    for user_indices, book_indices, ratings in test_loader:\n",
    "        user_indices, book_indices, ratings = user_indices.to(device), book_indices.to(device), ratings.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(user_indices, book_indices)\n",
    "        loss = criterion(outputs, ratings)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "\n",
    "# Average loss\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test MSE: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Books: ['0586092269', '0886777399', '0020303750', '0099296810', '0307204030']\n"
     ]
    }
   ],
   "source": [
    "def recommend_books(model, user_id_encoded, book_ids_encoded, num_recommendations=5):\n",
    "    model.eval()\n",
    "    user_indices = torch.tensor([user_id_encoded] * len(book_ids_encoded), dtype=torch.long).to(device)\n",
    "    book_indices = torch.tensor(book_ids_encoded, dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_indices, book_indices).cpu().numpy()\n",
    "    \n",
    "    # Get the top N recommendations; argsort sorts in ascending order, so use [-num_recommendations:]\n",
    "    recommended_indices = np.argsort(predictions)[-num_recommendations:]\n",
    "    \n",
    "    # Decode book IDs if necessary\n",
    "    recommended_books = [book_encoder.inverse_transform([idx])[0] for idx in recommended_indices]\n",
    "    \n",
    "    return recommended_books\n",
    "\n",
    "# Example usage\n",
    "user_id_encoded = user_encoder.transform([809])[0]  # Replace 'user_id_example' with actual user ID\n",
    "book_ids_encoded = list(range(len(book_encoder.classes_)))  # All books\n",
    "recommended_books = recommend_books(model, user_id_encoded, book_ids_encoded, num_recommendations=5)\n",
    "print(\"Recommended Books:\", recommended_books)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
